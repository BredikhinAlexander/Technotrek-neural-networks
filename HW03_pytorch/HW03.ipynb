{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HW03.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t6MzdEyYgBx"
      },
      "source": [
        "# ДЗ №3 \n",
        "## Обучение моделей глубокого обучения на PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnsPdf0WYgBy",
        "outputId": "9831301e-1fc0-43eb-8960-37613fb6c743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "!pip3 install torch torchvision numpy matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvLQ_YBQYgB2"
      },
      "source": [
        "Ваша задача на этой неделе - повторить модель трёхслойного перцептрона из прошолго задания на **PyTorch**, разобрать лучшие практики обучения моделей глубокого обучения и провести серию экспериментов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__30mGL7YgB2"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from typing import Tuple, List, Type, Dict, Any"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrhEDztvYgB5"
      },
      "source": [
        "Для того, чтобы эксперимент можно было повторить, хорошей практикой будет зафиксировать генератор случайных чисел. Также, рекоммендуется зафиксировать RNG в numpy и, если в качестве бэкенда используется cudnn - включить детерминированный режим.\n",
        "\n",
        "Подробнее: https://pytorch.org/docs/stable/notes/randomness.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uWe9MlmYgB6"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAWY8jLUYgB9"
      },
      "source": [
        "### Модель\n",
        "\n",
        "Основным способом организации кода на **Pytorch** является модуль. Простые модели могут быть реализованны из готовых модулей ( к примеру, `torch.nn.Sequential`, `torch.nn.Linear` и т.д. ), для более сложных архитектур часто приходтся реализовывать собственные блоки. Это достаточно легко сделать - достаточно написать класс, наследуемый от `torch.nn.Module` и реализующий метод `.forward`, который принимает и возвращает тензоры ( `torch.Tensor` )\n",
        "\n",
        "Пример реализации кастомного модуля из официальной документации: https://pytorch.org/tutorials/beginner/pytorch_with_examples.html3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk6a-pOnYgB-"
      },
      "source": [
        "#### Задание 1\n",
        "\n",
        "Повторите реализацию трёхслойного перцептрона из предыдущего задания на **Pytorch**. Желательно также, чтобы реализация модели имела параметризуемую глубину ( количество слоёв ), количество параметров на каждом слое и функцию активации. Отсутствие такой возможности не снижает балл, но сильно поможет в освоении принципов построения нейросетей с применением библиотеки pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2j_inpIYgB_"
      },
      "source": [
        "class Perceptron(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 input_resolution: Tuple[int, int] = (28, 28),\n",
        "                 input_channels: int = 1, \n",
        "                 hidden_layer_features: List[int] = [256, 256, 256],\n",
        "                 activation: Type[torch.nn.Module] = torch.nn.ReLU,\n",
        "                 num_classes: int = 10,\n",
        "                 n_hidden_neurons = 100):\n",
        "\n",
        "        super(Perceptron, self).__init__()\n",
        "        self.layer_1 = torch.nn.Linear(input_resolution[0] * input_resolution[1], n_hidden_neurons)\n",
        "        self.act_1 = torch.nn.Sigmoid()\n",
        "        self.layer_2 = torch.nn.Linear(n_hidden_neurons, num_classes)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.act_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        return x "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0QtMSeDfSVm"
      },
      "source": [
        "Заметим, что тут мы не считаем softmax на выходе, чтобы получить вероятности принадлежности к классам. Это делаем осознано, так как в pytorch есть функция CrossEntropyLoss, которая включает в себя взятие softmax и затем кросс-энтропии, но она более вычислительно стабильна и работает быстрее (так написано в документации)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi_YTtUlYgCC"
      },
      "source": [
        "Следующий код позволяет посмотреть архитектуру получившейся модели и общее количество обучаемых параметров. Мы хотим, чтобы количество параметров в модели было порядка сотен тысяч. Если у вас получается больше или меньше, попробуйте изменить архитектуру модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48AMXibrYgCD",
        "outputId": "ae511eee-5ba6-44f1-ee15-4df7494b62f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "model = Perceptron()\n",
        "print(model)\n",
        "print('Total number of trainable parameters', \n",
        "      sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Perceptron(\n",
            "  (layer_1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (act_1): Sigmoid()\n",
            "  (layer_2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "Total number of trainable parameters 79510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xBTX3EYgKRI"
      },
      "source": [
        "получили модель, у которой примерно 80000 параметров (условие, что порядка 100 000 выполнено)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7bMd6OQYgCF"
      },
      "source": [
        "### Обучающая выборка\n",
        "\n",
        "На практике, наиболее важным для успеха обучения любой модели машинного обучения является этап подготовки данных. Модели глубокого обучения не являются исключением. Большая, чистая, репрезентативная и релевантная поставленной задаче обучающая выборка часто важнее, чем архитектура самой модели. В предлагаемой задаче используется качественный и проверенный временем MNIST. Однако в практических задачах часто будет получаться так, что лучшим способом добиться улучшения качества модели будет сбор дополнительных данных и очистка исходных данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "143ridIdYgCG"
      },
      "source": [
        "### Предобработка данных\n",
        "\n",
        "Для улучшения сходимости алгоритма обучения и качества полученной модели данные могут быть предварительно обработаны:\n",
        "\n",
        "1. Среднее каждой входной переменной близко к нулю\n",
        "2. Переменные отмасштабированы таким образом, что их дисперсии примерно одинаковы ( из соображений вычислительной устойчивости, мы хотим, чтобы все величины по порядку величины были близки к еденице )\n",
        "3. По возможности, входные переменные не должны быть скоррелированны. Важнось этого пункта в последние годы ставится под сомнение, но всё-же в некоторых случаях это может влиять на результат\n",
        "\n",
        "Подробнее можно почитать здесь: http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPHpdmehYgCG"
      },
      "source": [
        "### Аугментация (искусственное дополнение) обучающей выборки\n",
        "\n",
        "В зависимости от задачи можно применять к признаковому описанию объектов обучающей выборки различные преобразования, которые позволят увеличить эффективный размер выборки без дополнительной разметки. К примеру, для задачи классификации кошек и собак можно зеркально отразить изображение вокруг вертикальной оси - при этом класс изображения не изменится, а само изображение останется по прежнему будет принадлежать исходному распределению. Есть много разных техник аугментации, и их применимость и эффективность сильно зависит от данных и задачи.\n",
        "\n",
        "Подробнее можно почитать здесь: https://link.springer.com/content/pdf/10.1186/s40537-019-0197-0.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZyzyU2eYgCH"
      },
      "source": [
        "### Задание 2\n",
        "\n",
        "Обоснуйте, почему аугментация обучающей выборки позволяет добиться прироста качества модели, несмотря на то, что она не добавляет в неё дополнительную информацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvywyKMRYgCI"
      },
      "source": [
        "#Your text here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKGjRHrFYgCJ"
      },
      "source": [
        "### Задание 3\n",
        "\n",
        "Какие осмысленные аугментации вы можете придумать для следующих наборов данных:\n",
        "\n",
        "1. Набор изображений животных, размеченый на виды животных\n",
        "2. Набор аудиозаписей голоса, размечеными на языки говорящего\n",
        "3. Набор cо показаниями датчиков температуры, влажности и давления с одной из метеостанций, размеченый на признак наличия осадков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VLpLhKPYgCJ"
      },
      "source": [
        "#Your text here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au2RKhNuYgCK"
      },
      "source": [
        "### Задание 4\n",
        "\n",
        "Напишите пайплайн для предобработки и аугументации данных. В `torchvision.transforms` есть готовые реализации большинства распространённых техник. Если вы хотите добавить что-то своё, вы можете воспользоваться `torchvision.transforms.Lambda`. При этом следует понимать, что если нужно оценить качество модели на оригинальных данных, пайплайн предварительной обработки данных валидационной выборки не должен включать аугментаций. Следует помнить, однако, что существует подход аугментации данных в момент применения модели (test-time augmentation), который позволяет повысить качество модели в режиме исполнения.\n",
        "\n",
        "Одним из обязательных шагов в вашем пайплайне должна быть конвертация данных в тензоры Pytorch (`torch.Tensor`): `torchvision.transforms.ToTensor()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swagm8D5YgCK"
      },
      "source": [
        "train_transforms = torchvision.transforms.Compose([\n",
        "                                                 \n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.5,), (1.0,)),\n",
        "    #transforms.Resize((28*28))\n",
        "])\n",
        "\n",
        "val_transforms = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.5,), (1.0,))\n",
        "])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS3BIW_YyFAw"
      },
      "source": [
        "В трансформации данных переводим картинку в тензор, с помощью transforms.ToTensor() и нормализуем её\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iYE63CXYgCN"
      },
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./mnist', \n",
        "                                           train=True, \n",
        "                                           download=True,\n",
        "                                           transform=train_transforms)\n",
        "\n",
        "val_dataset = torchvision.datasets.MNIST(root='./mnist', \n",
        "                                         train=False, \n",
        "                                         download=True, \n",
        "                                         transform=val_transforms)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uibRZF7FysyR",
        "outputId": "40509118-8735-4c45-eaf8-f11256f0f2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(train_dataset)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./mnist\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5,), std=(1.0,))\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD9NQlI1xdTs",
        "outputId": "97e333ee-8da2-4521-ccea-52b645930027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "X_train = train_dataset.train_data # делаем данные для test и train для нашей нейронной сети\n",
        "y_train = train_dataset.train_labels\n",
        "X_test = val_dataset.test_data\n",
        "y_test = val_dataset.test_labels"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEp2iTCRx_yb",
        "outputId": "3b495bea-facd-4484-928d-334b1f55e86d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZFy4p87hA3O"
      },
      "source": [
        "X_train = X_train.reshape([-1, 28 * 28]) # переводим трёхмерный тензор в двумерный\n",
        "X_test = X_test.reshape([-1, 28 * 28])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8djodWSGmS5",
        "outputId": "fa09eed0-416d-455e-ad3f-b768e2c9f254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "train_dataset.train_data.shape\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE_Hvllaz8hU",
        "outputId": "4c890968-3610-4727-92b6-ba0ceacd545b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gKs62EshI--"
      },
      "source": [
        "Для начала просто преобразуем трёхмерный тензор, который поступает нам на вход, в двумерный (растянем картинку 28*28 в одну линию). Да, тем самымым мы потеряем информацию о том, какие пиксели находятся рядом, какие нет, но зато мы сможем применить наш многослойный Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpSo-K1C07ah"
      },
      "source": [
        "Возможно это можно было сделать внутри класса torchvision.transforms.Compose, но я не разобралась как. Поэтому сделала это вне класса используя просто reshape, который подбирает первую зависимость автоматически, а вторую делает 28*28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZHTftrFKnUr"
      },
      "source": [
        "Потом все равно использую dataloader, поэтому делаю reshape внутри каждой эпохи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVj2cekRYgCQ"
      },
      "source": [
        "Перед тем как запускать обучение всегда стоит посмотреть на данные после предобработки, и удостовериться, что они соответствуют ожидаемым"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a54G3Kv51e8T"
      },
      "source": [
        "Не понимаю, как работает этот кусок кода..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKB5FXYMYgCQ"
      },
      "source": [
        "indices = np.random.randint(0, len(train_dataset), size=256)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=16, ncols=16, figsize=(32, 32))\n",
        "for i, row in enumerate(axes):\n",
        "    for j, ax in enumerate(row):\n",
        "        sample_index = indices[i*16+j]\n",
        "        sample, label = train_dataset[sample_index]\n",
        "        #print(sample.cpu().numpy().transpose(1, 2, 0))\n",
        "        ax.imshow(sample.cpu().numpy().transpose(1, 2, 0))\n",
        "        ax.set_title(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYr8Gsx0YgCT"
      },
      "source": [
        "### Обучение модели\n",
        "\n",
        "Теперь, когда мы реализовали модель и подготовили данные мы можем приступить к непосредственному обучению модели. Костяк функции обучения написан ниже, далее вы должны будете реализовать ключевые части этого алгоритма"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsTzUgvYYgCT"
      },
      "source": [
        "def train_model(model: torch.nn.Module, \n",
        "                train_dataset: torch.utils.data.Dataset,\n",
        "                val_dataset: torch.utils.data.Dataset,\n",
        "                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n",
        "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n",
        "                optimizer_params: Dict = {},\n",
        "                initial_lr = 0.01,\n",
        "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "                lr_scheduler_params: Dict = {},\n",
        "                batch_size = 64,\n",
        "                max_epochs = 1000,\n",
        "                early_stopping_patience = 20):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, **optimizer_params)\n",
        "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    best_val_loss = None\n",
        "    best_epoch = None\n",
        "    loss_hist_train = []\n",
        "    accuracy_hist_train = []\n",
        "\n",
        "    loss_hist_val = []\n",
        "    accuracy_hist_val = []\n",
        "    for epoch in range(max_epochs):\n",
        "        \n",
        "        print(f'Epoch {epoch}')\n",
        "        metric_train = train_single_epoch(model, optimizer, loss_function, train_loader)\n",
        "        loss_hist_val.append(metric_train['loss'])\n",
        "        accuracy_hist_val.append(metric_train['accuracy'])\n",
        "        val_metrics = validate_single_epoch(model, loss_function, val_loader)\n",
        "        loss_hist_train.append(val_metrics['loss'])\n",
        "        accuracy_hist_train.append(val_metrics['accuracy'])\n",
        "        print(f'Validation metrics: \\n{val_metrics}')\n",
        "\n",
        "        lr_scheduler.step(val_metrics['loss'])\n",
        "        \n",
        "        if best_val_loss is None or best_val_loss > val_metrics['loss']:\n",
        "            print(f'Best model yet, saving')\n",
        "            best_val_loss = val_metrics['loss']\n",
        "            best_epoch = epoch\n",
        "            torch.save(model, './best_model.pth')\n",
        "            \n",
        "        if epoch - best_epoch > early_stopping_patience:\n",
        "            print('Early stopping triggered')\n",
        "            return\n",
        "    return loss_hist_train, accuracy_hist_train, loss_hist_val, accuracy_hist_val"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua0KyJv7YgCY"
      },
      "source": [
        "### Задание 5\n",
        "\n",
        "Реализуйте функцию, производящую обучение сети на протяжении одной эпохи ( полного прохода по всей обучающей выборке ). На вход будет приходить модель, оптимизатор, функция потерь и объект типа `DataLoader`. При итерировании по `data_loader` вы будете получать пары вида ( данные, целевая_переменная )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XereEiJaYgCY"
      },
      "source": [
        "def train_single_epoch(model: torch.nn.Module,\n",
        "                       optimizer: torch.optim.Optimizer, \n",
        "                       loss_function: torch.nn.Module, \n",
        "                       data_loader: torch.utils.data.DataLoader):\n",
        "    loss_history = []\n",
        "    accuracy_history = []\n",
        "    for X, y in data_loader:\n",
        "      X_batch = X.reshape([-1, 28 * 28])\n",
        "\n",
        "      X_batch = X_batch.to(device) # переносим на видеопамять для вычисления (для скорости обучения делаю на colab)\n",
        "      y = y.to(device)\n",
        "\n",
        "\n",
        "      optimizer.zero_grad() # обнуляем градиент, так как он не обнуляется с предыдущей итерации\n",
        "\n",
        "      pred = model.forward(X_batch) # получаю предсказание модели\n",
        "\n",
        "      loss_value = loss_function(pred, y) # значение лосс функции на батче\n",
        "      loss_history.append(loss_value)\n",
        "      accuracy = (pred.argmax(dim=1) == y).float().mean() # точность это сколько из возможных угадала наша модель\n",
        "      accuracy_history.append(accuracy)\n",
        "      loss_value.backward() # производная по каждой из компонент нашей нейронной сети\n",
        "\n",
        "      optimizer.step() # делаем шаг нашего оптимизатора\n",
        "    return {'loss': float(sum(loss_history)/len(loss_history)), 'accuracy': float(sum(accuracy_history)/len(accuracy_history))}"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghhuujMZYgCb"
      },
      "source": [
        "### Задание 6\n",
        "\n",
        "Реализуйте функцию производящую вычисление функции потерь на валидационной выборке.  На вход будет приходить модель, функция потерь и `DataLoader`. На выходе ожидается словарь с вида:\n",
        "```\n",
        "{\n",
        "    'loss': <среднее значение функции потерь>,\n",
        "    'accuracy': <среднее значение точности модели>\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOtfpMC0YgCb"
      },
      "source": [
        "def validate_single_epoch(model: torch.nn.Module,\n",
        "                          loss_function: torch.nn.Module, \n",
        "                          data_loader: torch.utils.data.DataLoader):\n",
        "    loss_history = []\n",
        "    accuracy_history = []\n",
        "    accuracy = 0\n",
        "    for X, y in data_loader:\n",
        "      X_test = X.reshape([-1, 28 * 28])\n",
        "      pred_test = model.forward(X_test)  # получаем результат на валидации\n",
        "\n",
        "      loss_val = loss_function(pred_test, y) # лосс функция на валидации на одном батче\n",
        "      loss_history.append(loss_val) #  добавляем в массив значение лосс функции на батче\n",
        "      accuracy = (pred_test.argmax(dim=1) == y).float().mean() # точность это сколько из возможных угадала наша модель\n",
        "      accuracy_history.append(accuracy)\n",
        "      \n",
        "    res_dict = {'loss': float(sum(loss_history)/len(loss_history)), 'accuracy': float(sum(accuracy_history)/len(accuracy_history))}\n",
        "    return res_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHY77Q4tYgCe"
      },
      "source": [
        "Если вы корректно реализовали все предыдущие шаги и ваша модель имеет достаточное количество обучаемых параметров, то в следующей ячейке должен пойти процесс обучения, и мы должны достичь итоговой точности (в смысле меры accuracy, доли верных ответов) выше 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1oEJfOCXSw7"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # если видеокарта доступно, будем переносить туда вычисления\n",
        "model = model.to(device) # все параметры нейронной сети переносим на видеопамять, так как с ними вычисления происходят очень часто\n",
        "# list(mnist_net.parameters()) # проверяем, что все веса и байесы переместились"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngBwK-BQYgCe",
        "outputId": "7e049044-962b-4b14-c252-8e6e66edeac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_model(model, \n",
        "            train_dataset=train_dataset, \n",
        "            val_dataset=val_dataset, \n",
        "            loss_function=torch.nn.CrossEntropyLoss(), \n",
        "            initial_lr=0.01)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Validation metrics: \n",
            "{'loss': 0.16420666873455048, 'accuracy': 0.9523288011550903}\n",
            "Best model yet, saving\n",
            "Epoch 1\n",
            "Validation metrics: \n",
            "{'loss': 0.17256665229797363, 'accuracy': 0.9499402642250061}\n",
            "Epoch 2\n",
            "Validation metrics: \n",
            "{'loss': 0.17492757737636566, 'accuracy': 0.9492436051368713}\n",
            "Epoch 3\n",
            "Validation metrics: \n",
            "{'loss': 0.15717710554599762, 'accuracy': 0.956409215927124}\n",
            "Best model yet, saving\n",
            "Epoch 4\n",
            "Validation metrics: \n",
            "{'loss': 0.1613512635231018, 'accuracy': 0.9550158977508545}\n",
            "Epoch 5\n",
            "Validation metrics: \n",
            "{'loss': 0.1752701997756958, 'accuracy': 0.9487460255622864}\n",
            "Epoch 6\n",
            "Validation metrics: \n",
            "{'loss': 0.1733340322971344, 'accuracy': 0.9505374431610107}\n",
            "Epoch 7\n",
            "Validation metrics: \n",
            "{'loss': 0.16027899086475372, 'accuracy': 0.9541202187538147}\n",
            "Epoch 8\n",
            "Validation metrics: \n",
            "{'loss': 0.15008753538131714, 'accuracy': 0.9565087556838989}\n",
            "Best model yet, saving\n",
            "Epoch 9\n",
            "Validation metrics: \n",
            "{'loss': 0.14529071748256683, 'accuracy': 0.9568073153495789}\n",
            "Best model yet, saving\n",
            "Epoch 10\n",
            "Validation metrics: \n",
            "{'loss': 0.17278291285037994, 'accuracy': 0.9512341022491455}\n",
            "Epoch 11\n",
            "Validation metrics: \n",
            "{'loss': 0.1894872635602951, 'accuracy': 0.9455612897872925}\n",
            "Epoch 12\n",
            "Validation metrics: \n",
            "{'loss': 0.17617911100387573, 'accuracy': 0.9489450454711914}\n",
            "Epoch 13\n",
            "Validation metrics: \n",
            "{'loss': 0.18025559186935425, 'accuracy': 0.9486464858055115}\n",
            "Epoch 14\n",
            "Validation metrics: \n",
            "{'loss': 0.15018408000469208, 'accuracy': 0.9543192386627197}\n",
            "Epoch 15\n",
            "Validation metrics: \n",
            "{'loss': 0.1658027619123459, 'accuracy': 0.9518312215805054}\n",
            "Epoch 16\n",
            "Validation metrics: \n",
            "{'loss': 0.15517652034759521, 'accuracy': 0.952925980091095}\n",
            "Epoch 17\n",
            "Validation metrics: \n",
            "{'loss': 0.16963917016983032, 'accuracy': 0.9515326619148254}\n",
            "Epoch 18\n",
            "Validation metrics: \n",
            "{'loss': 0.17322568595409393, 'accuracy': 0.9501393437385559}\n",
            "Epoch 19\n",
            "Validation metrics: \n",
            "{'loss': 0.16246885061264038, 'accuracy': 0.9526273608207703}\n",
            "Epoch 20\n",
            "Validation metrics: \n",
            "{'loss': 0.1760471761226654, 'accuracy': 0.9514331221580505}\n",
            "Epoch 21\n",
            "Validation metrics: \n",
            "{'loss': 0.13382984697818756, 'accuracy': 0.9600915312767029}\n",
            "Best model yet, saving\n",
            "Epoch 22\n",
            "Validation metrics: \n",
            "{'loss': 0.13560278713703156, 'accuracy': 0.9608877301216125}\n",
            "Epoch 23\n",
            "Validation metrics: \n",
            "{'loss': 0.13316842913627625, 'accuracy': 0.9599920511245728}\n",
            "Best model yet, saving\n",
            "Epoch 24\n",
            "Validation metrics: \n",
            "{'loss': 0.1318412870168686, 'accuracy': 0.9628781676292419}\n",
            "Best model yet, saving\n",
            "Epoch 25\n",
            "Validation metrics: \n",
            "{'loss': 0.13259360194206238, 'accuracy': 0.9616839289665222}\n",
            "Epoch 26\n",
            "Validation metrics: \n",
            "{'loss': 0.1320401281118393, 'accuracy': 0.962380588054657}\n",
            "Epoch 27\n",
            "Validation metrics: \n",
            "{'loss': 0.1324978470802307, 'accuracy': 0.9616839289665222}\n",
            "Epoch 28\n",
            "Validation metrics: \n",
            "{'loss': 0.13586510717868805, 'accuracy': 0.9630772471427917}\n",
            "Epoch 29\n",
            "Validation metrics: \n",
            "{'loss': 0.13154414296150208, 'accuracy': 0.962082028388977}\n",
            "Best model yet, saving\n",
            "Epoch 30\n",
            "Validation metrics: \n",
            "{'loss': 0.12994569540023804, 'accuracy': 0.9619824886322021}\n",
            "Best model yet, saving\n",
            "Epoch 31\n",
            "Validation metrics: \n",
            "{'loss': 0.13577067852020264, 'accuracy': 0.9614848494529724}\n",
            "Epoch 32\n",
            "Validation metrics: \n",
            "{'loss': 0.1330460011959076, 'accuracy': 0.962380588054657}\n",
            "Epoch 33\n",
            "Validation metrics: \n",
            "{'loss': 0.13357047736644745, 'accuracy': 0.9622810482978821}\n",
            "Epoch 34\n",
            "Validation metrics: \n",
            "{'loss': 0.13459524512290955, 'accuracy': 0.9621815085411072}\n",
            "Epoch 35\n",
            "Validation metrics: \n",
            "{'loss': 0.13460788130760193, 'accuracy': 0.9606887102127075}\n",
            "Epoch 36\n",
            "Validation metrics: \n",
            "{'loss': 0.1329522281885147, 'accuracy': 0.9619824886322021}\n",
            "Epoch 37\n",
            "Validation metrics: \n",
            "{'loss': 0.1349509358406067, 'accuracy': 0.9624800682067871}\n",
            "Epoch 38\n",
            "Validation metrics: \n",
            "{'loss': 0.13826999068260193, 'accuracy': 0.9618829488754272}\n",
            "Epoch 39\n",
            "Validation metrics: \n",
            "{'loss': 0.13603873550891876, 'accuracy': 0.9615843892097473}\n",
            "Epoch 40\n",
            "Validation metrics: \n",
            "{'loss': 0.13658516108989716, 'accuracy': 0.9616839289665222}\n",
            "Epoch 41\n",
            "Validation metrics: \n",
            "{'loss': 0.13887636363506317, 'accuracy': 0.962082028388977}\n",
            "Epoch 42\n",
            "Validation metrics: \n",
            "{'loss': 0.13660120964050293, 'accuracy': 0.9621815085411072}\n",
            "Epoch 43\n",
            "Validation metrics: \n",
            "{'loss': 0.13652239739894867, 'accuracy': 0.9621815085411072}\n",
            "Epoch 44\n",
            "Validation metrics: \n",
            "{'loss': 0.13672839105129242, 'accuracy': 0.962082028388977}\n",
            "Epoch 45\n",
            "Validation metrics: \n",
            "{'loss': 0.13678699731826782, 'accuracy': 0.9621815085411072}\n",
            "Epoch 46\n",
            "Validation metrics: \n",
            "{'loss': 0.13693077862262726, 'accuracy': 0.9621815085411072}\n",
            "Epoch 47\n",
            "Validation metrics: \n",
            "{'loss': 0.13695548474788666, 'accuracy': 0.962082028388977}\n",
            "Epoch 48\n",
            "Validation metrics: \n",
            "{'loss': 0.1365593522787094, 'accuracy': 0.9621815085411072}\n",
            "Epoch 49\n",
            "Validation metrics: \n",
            "{'loss': 0.13646629452705383, 'accuracy': 0.9621815085411072}\n",
            "Epoch 50\n",
            "Validation metrics: \n",
            "{'loss': 0.13711155951023102, 'accuracy': 0.9622810482978821}\n",
            "Epoch 51\n",
            "Validation metrics: \n",
            "{'loss': 0.1361342817544937, 'accuracy': 0.9622810482978821}\n",
            "Early stopping triggered\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiJR5hFEgAJP"
      },
      "source": [
        "Выше представлено обучение модели, которая достигла точности 96.22\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN7wNyigYgCh"
      },
      "source": [
        "### Задание 7\n",
        "\n",
        "Модифицируйте процесс обучения таким образом, чтобы достигнуть наилучшего качества на валидационной выборке. Модель должна оставаться N-слойным перцептроном с количеством обучаемых параметров <= 500000. Для обучения разрешается использовать только набор данных MNIST. Процесс обучения вы можете изменять по собственному усмотрению. К примеру, вы можете менять:\n",
        "\n",
        "* Архитектуру модели в рамках наложенных ограничений на количество параметров и вид архитектуры (многослойный перцептрон)\n",
        "* Функции активации в модели\n",
        "* Используемый оптимизатор\n",
        "* Расписание шага оптимизации\n",
        "* Сэмплинг данных при обучении ( e.g. hard negative mining)\n",
        "\n",
        "В результате мы ожидаем увидеть код экспериментов и любые инсайты, которые вы сможете получить в процессе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY5IuA3MkCQe",
        "outputId": "198c81ad-126b-469b-b476-e79227b8ebfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loss_hist_train, accuracy_hist_train, loss_hist_val, accuracy_hist_val = train_model(model, \n",
        "            train_dataset=train_dataset, \n",
        "            val_dataset=val_dataset, \n",
        "            loss_function=torch.nn.CrossEntropyLoss(), \n",
        "            initial_lr=0.01)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Validation metrics: \n",
            "{'loss': 0.17392483353614807, 'accuracy': 0.9525278806686401}\n",
            "Best model yet, saving\n",
            "Epoch 1\n",
            "Validation metrics: \n",
            "{'loss': 0.15757401287555695, 'accuracy': 0.9566082954406738}\n",
            "Best model yet, saving\n",
            "Epoch 2\n",
            "Validation metrics: \n",
            "{'loss': 0.16630908846855164, 'accuracy': 0.9534235596656799}\n",
            "Epoch 3\n",
            "Validation metrics: \n",
            "{'loss': 0.15263965725898743, 'accuracy': 0.9589968323707581}\n",
            "Best model yet, saving\n",
            "Epoch 4\n",
            "Validation metrics: \n",
            "{'loss': 0.1704322099685669, 'accuracy': 0.9541202187538147}\n",
            "Epoch 5\n",
            "Validation metrics: \n",
            "{'loss': 0.16922439634799957, 'accuracy': 0.9520302414894104}\n",
            "Epoch 6\n",
            "Validation metrics: \n",
            "{'loss': 0.1734420210123062, 'accuracy': 0.9532245397567749}\n",
            "Epoch 7\n",
            "Validation metrics: \n",
            "{'loss': 0.17181943356990814, 'accuracy': 0.9499402642250061}\n",
            "Epoch 8\n",
            "Validation metrics: \n",
            "{'loss': 0.15559880435466766, 'accuracy': 0.9575039744377136}\n",
            "Epoch 9\n",
            "Validation metrics: \n",
            "{'loss': 0.1765182465314865, 'accuracy': 0.9506369233131409}\n",
            "Epoch 10\n",
            "Validation metrics: \n",
            "{'loss': 0.15766778588294983, 'accuracy': 0.9563097357749939}\n",
            "Epoch 11\n",
            "Validation metrics: \n",
            "{'loss': 0.1639968603849411, 'accuracy': 0.9524283409118652}\n",
            "Epoch 12\n",
            "Validation metrics: \n",
            "{'loss': 0.1655476838350296, 'accuracy': 0.952925980091095}\n",
            "Epoch 13\n",
            "Validation metrics: \n",
            "{'loss': 0.15816675126552582, 'accuracy': 0.9524283409118652}\n",
            "Epoch 14\n",
            "Validation metrics: \n",
            "{'loss': 0.1655566692352295, 'accuracy': 0.9538216590881348}\n",
            "Epoch 15\n",
            "Validation metrics: \n",
            "{'loss': 0.13331851363182068, 'accuracy': 0.9627786874771118}\n",
            "Best model yet, saving\n",
            "Epoch 16\n",
            "Validation metrics: \n",
            "{'loss': 0.12944073975086212, 'accuracy': 0.9628781676292419}\n",
            "Best model yet, saving\n",
            "Epoch 17\n",
            "Validation metrics: \n",
            "{'loss': 0.1310155689716339, 'accuracy': 0.9628781676292419}\n",
            "Epoch 18\n",
            "Validation metrics: \n",
            "{'loss': 0.1282804012298584, 'accuracy': 0.9655652642250061}\n",
            "Best model yet, saving\n",
            "Epoch 19\n",
            "Validation metrics: \n",
            "{'loss': 0.1315631866455078, 'accuracy': 0.9639729261398315}\n",
            "Epoch 20\n",
            "Validation metrics: \n",
            "{'loss': 0.12797577679157257, 'accuracy': 0.9640724658966064}\n",
            "Best model yet, saving\n",
            "Epoch 21\n",
            "Validation metrics: \n",
            "{'loss': 0.12745553255081177, 'accuracy': 0.9642714858055115}\n",
            "Best model yet, saving\n",
            "Epoch 22\n",
            "Validation metrics: \n",
            "{'loss': 0.13103696703910828, 'accuracy': 0.9640724658966064}\n",
            "Epoch 23\n",
            "Validation metrics: \n",
            "{'loss': 0.12966890633106232, 'accuracy': 0.9630772471427917}\n",
            "Epoch 24\n",
            "Validation metrics: \n",
            "{'loss': 0.13050809502601624, 'accuracy': 0.9642714858055115}\n",
            "Epoch 25\n",
            "Validation metrics: \n",
            "{'loss': 0.12728939950466156, 'accuracy': 0.9639729261398315}\n",
            "Best model yet, saving\n",
            "Epoch 26\n",
            "Validation metrics: \n",
            "{'loss': 0.12782655656337738, 'accuracy': 0.9642714858055115}\n",
            "Epoch 27\n",
            "Validation metrics: \n",
            "{'loss': 0.12835654616355896, 'accuracy': 0.9638733863830566}\n",
            "Epoch 28\n",
            "Validation metrics: \n",
            "{'loss': 0.1264270544052124, 'accuracy': 0.9644705653190613}\n",
            "Best model yet, saving\n",
            "Epoch 29\n",
            "Validation metrics: \n",
            "{'loss': 0.1319965422153473, 'accuracy': 0.9635748267173767}\n",
            "Epoch 30\n",
            "Validation metrics: \n",
            "{'loss': 0.12830741703510284, 'accuracy': 0.9644705653190613}\n",
            "Epoch 31\n",
            "Validation metrics: \n",
            "{'loss': 0.12692393362522125, 'accuracy': 0.9650676846504211}\n",
            "Epoch 32\n",
            "Validation metrics: \n",
            "{'loss': 0.1281113475561142, 'accuracy': 0.9637739062309265}\n",
            "Epoch 33\n",
            "Validation metrics: \n",
            "{'loss': 0.12963683903217316, 'accuracy': 0.9642714858055115}\n",
            "Epoch 34\n",
            "Validation metrics: \n",
            "{'loss': 0.12920337915420532, 'accuracy': 0.9647691249847412}\n",
            "Epoch 35\n",
            "Validation metrics: \n",
            "{'loss': 0.12902706861495972, 'accuracy': 0.9639729261398315}\n",
            "Epoch 36\n",
            "Validation metrics: \n",
            "{'loss': 0.1315384954214096, 'accuracy': 0.9640724658966064}\n",
            "Epoch 37\n",
            "Validation metrics: \n",
            "{'loss': 0.1312035322189331, 'accuracy': 0.9626791477203369}\n",
            "Epoch 38\n",
            "Validation metrics: \n",
            "{'loss': 0.13106447458267212, 'accuracy': 0.9640724658966064}\n",
            "Epoch 39\n",
            "Validation metrics: \n",
            "{'loss': 0.13053502142429352, 'accuracy': 0.9634753465652466}\n",
            "Epoch 40\n",
            "Validation metrics: \n",
            "{'loss': 0.13014303147792816, 'accuracy': 0.9642714858055115}\n",
            "Epoch 41\n",
            "Validation metrics: \n",
            "{'loss': 0.12996000051498413, 'accuracy': 0.9641719460487366}\n",
            "Epoch 42\n",
            "Validation metrics: \n",
            "{'loss': 0.13005252182483673, 'accuracy': 0.9644705653190613}\n",
            "Epoch 43\n",
            "Validation metrics: \n",
            "{'loss': 0.1301134079694748, 'accuracy': 0.9639729261398315}\n",
            "Epoch 44\n",
            "Validation metrics: \n",
            "{'loss': 0.13022011518478394, 'accuracy': 0.9640724658966064}\n",
            "Epoch 45\n",
            "Validation metrics: \n",
            "{'loss': 0.13038603961467743, 'accuracy': 0.9643710255622864}\n",
            "Epoch 46\n",
            "Validation metrics: \n",
            "{'loss': 0.1304735243320465, 'accuracy': 0.9640724658966064}\n",
            "Epoch 47\n",
            "Validation metrics: \n",
            "{'loss': 0.1304759383201599, 'accuracy': 0.9639729261398315}\n",
            "Epoch 48\n",
            "Validation metrics: \n",
            "{'loss': 0.13037362694740295, 'accuracy': 0.9636743664741516}\n",
            "Epoch 49\n",
            "Validation metrics: \n",
            "{'loss': 0.1306818574666977, 'accuracy': 0.9640724658966064}\n",
            "Early stopping triggered\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-dfb770997399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             initial_lr=0.01)\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYUFlEfjarMy",
        "outputId": "fbc3e276-4af9-4524-9696-e611e2167200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "plt.plot(loss_hist_train, label='loss function Test') # график убывания loss функции от номера эпохи\n",
        "plt.plot(loss_hist_val, label='loss function validation', c='r')\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('$n\\_epoxa$')\n",
        "plt.ylabel('$loss$')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f0350e861f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_hist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss function Test'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# график убывания loss функции от номера эпохи\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_hist_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss function validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'$n\\_epoxa$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'$loss$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss_hist_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89u8fBoZYgCh"
      },
      "source": [
        "plt.plot(accuracy_hist_val, c='r', label='accuracy_Test')\n",
        "plt.plot(accuracy_hist_train, c='g', label='accuracy_Train')\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('$n\\_epoxa$')\n",
        "plt.ylabel('$accuracy$')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}